apiVersion: batch/v1
kind: Job
metadata:
  name: chord-mini
  namespace: csuf-titans
  labels:
    app: chord-student-training
spec:
  backoffLimit: 2
  template:
    metadata:
      labels:
        app: chord-student-training
    spec:
      restartPolicy: Never
      tolerations:
        - key: "node.kubernetes.io/not-ready"
          operator: "Exists"
          effect: "NoExecute"
          tolerationSeconds: 86400
        - key: "node.kubernetes.io/unreachable"
          operator: "Exists"
          effect: "NoExecute"
          tolerationSeconds: 86400
      initContainers:
        - name: clone-repo
          image: alpine:3.16
          imagePullPolicy: IfNotPresent
          command:
            - sh
            - -c
            - |
              set -ex
              echo "Installing git..."
              apk update && apk add --no-cache git
              echo "Checking for existing project repository..."
              if [ ! -d "/mnt/storage/ChordMini" ]; then
                echo "Cloning repository..."
                git clone https://gitlab.com/ptnghia-j/ChordMini.git /mnt/storage/ChordMini || {
                  echo "ERROR: Failed to clone repository"
                  exit 1
                }
              else
                echo "Repository already exists."
              fi
              exit 0
          volumeMounts:
            - name: storage
              mountPath: /mnt/storage
        - name: data-check
          image: alpine:3.16
          imagePullPolicy: IfNotPresent
          command:
            - sh
            - -c
            - |
              set -ex
              echo "Checking data directory structure..."
              
              # Locate the spectrogram and label directories
              PROJ_ROOT="/mnt/storage/ChordMini"
              echo "Project root: $PROJ_ROOT"
              
              # Create the data directories if they don't exist
              mkdir -p "/mnt/storage/data/synth/spectrograms"
              mkdir -p "/mnt/storage/data/synth/labels"
              
              # Create symlinks from project directory to actual data location if needed
              mkdir -p "$PROJ_ROOT/data/synth"
              
              # Check if symlinks already exist
              if [ -L "$PROJ_ROOT/data/synth/spectrograms" ]; then
                echo "Symlink for spectrograms already exists"
              else
                ln -sf "/mnt/storage/data/synth/spectrograms" "$PROJ_ROOT/data/synth/spectrograms"
                echo "Created symlink for spectrograms"
              fi
              
              if [ -L "$PROJ_ROOT/data/synth/labels" ]; then
                echo "Symlink for labels already exists"
              else
                ln -sf "/mnt/storage/data/synth/labels" "$PROJ_ROOT/data/synth/labels"
                echo "Created symlink for labels"
              fi
              
              # Check for spectrogram files in the main and alternate locations
              echo "---- Checking for spectrogram files ----"
              find "/mnt/storage/data/synth" -name "*.npy" | head -10
              find "$PROJ_ROOT/data/synth" -name "*.npy" | head -10
              
              # Check for label files in the main and alternate locations
              echo "---- Checking for label files ----"
              find "/mnt/storage/data/synth" -name "*.lab" | head -10 
              find "$PROJ_ROOT/data/synth" -name "*.lab" | head -10
              
              # Verify there are some relevant files (but allow training to proceed regardless)
              echo "Checking if there are data files to process..."
              SPEC_COUNT=$(find "/mnt/storage/data/synth" -type f -name "*.npy" | wc -l)
              LABEL_COUNT=$(find "/mnt/storage/data/synth" -type f -name "*.lab" | wc -l)
              echo "Found $SPEC_COUNT spectrogram files and $LABEL_COUNT label files"
              if [ "$SPEC_COUNT" -eq 0 ] || [ "$LABEL_COUNT" -eq 0 ]; then
                echo "WARNING: No data files found. Training may fail."
              else
                echo "Data files found. Proceeding with training."
              fi
          volumeMounts:
            - name: storage
              mountPath: /mnt/storage
      containers:
        - name: student-trainer
          image: pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime
          workingDir: /mnt/storage/ChordMini
          imagePullPolicy: IfNotPresent
          env:
            # These environment variables override defaults in student_config.yaml
            - name: PYTHONPATH
              value: /mnt/storage/ChordMini
            # Model scale - overrides student_config.yaml
            - name: MODEL_SCALE
              value: "1.0"  # Default scale: 1.0 = base model, 0.5 = half-scale, 2.0 = double
            # Learning rate scheduling options - overrides student_config.yaml settings
            - name: LR_SCHEDULE
              value: "cosine"  # Options: cosine, linear_decay, one_cycle, cosine_warm_restarts
            - name: USE_WARMUP
              value: "true"    # Overrides use_warmup in student_config.yaml
            - name: WARMUP_EPOCHS
              value: "20"       # Overrides warmup_epochs in student_config.yaml
            # Focal loss options - overrides student_config.yaml settings
            - name: USE_FOCAL_LOSS
              value: "true"    # Overrides use_focal_loss in student_config.yaml
            - name: FOCAL_GAMMA
              value: "1.5"     # Overrides focal_gamma in student_config.yaml
            # Knowledge distillation options - overrides student_config.yaml settings
            - name: USE_KD_LOSS
              value: "true"   # Overrides use_kd_loss in student_config.yaml
            - name: KD_ALPHA
              value: "0.9"     # Overrides kd_alpha in student_config.yaml
            - name: TEMPERATURE
              value: "20.0"     # Overrides temperature in student_config.yaml
            - name: KD_DATA_ROOT
              value: "/mnt/storage/data/logits/synth"  # Base dir for KD data
            # Caching options
            - name: METADATA_CACHE
              value: "true"    # Set to "true" to enable metadata-only caching, "false" to disable all caching
            - name: CACHE_FRACTION
              value: "0.01"     # Cache only 1% of samples
          command:
            - sh
            - -c
            - |
              set -ex
              echo "=== Student model training container started ==="
              
              # Install necessary system packages
              apt-get update && apt-get install -y libsndfile1 || { echo "ERROR: Failed to install system dependencies"; exit 1; }
              
              # Create a minimal requirements.txt if missing
              if [ ! -f requirements.txt ]; then
                echo "Creating minimal requirements.txt"
                echo "numpy==1.22.0" > requirements.txt
                echo "librosa>=0.8.0" >> requirements.txt
                echo "torch>=1.9.0" >> requirements.txt
                echo "tqdm>=4.62.0" >> requirements.txt
                echo "scikit-learn>=1.0.0" >> requirements.txt
                echo "pyyaml>=6.0.0" >> requirements.txt  # Added for config loading
              fi
              
              pip install --no-cache-dir -r requirements.txt || { echo "WARNING: Some requirements may have failed"; }
              pip install --no-cache-dir matplotlib tqdm pyyaml librosa scikit-learn || { echo "ERROR: Failed to install additional Python packages"; exit 1; }
              
              # Verify the data paths from the config
              echo "Checking data paths from config..."
              grep -A 10 "paths:" ./config/student_config.yaml
              
              # Double check that the symlinks are still valid
              if [ ! -L "./data/synth/spectrograms" ]; then
                echo "Recreating symlink for spectrograms"
                mkdir -p ./data/synth
                ln -sf "/mnt/storage/data/synth/spectrograms" "./data/synth/spectrograms"
              fi
              
              if [ ! -L "./data/synth/labels" ]; then
                echo "Recreating symlink for labels"
                mkdir -p ./data/synth
                ln -sf "/mnt/storage/data/synth/labels" "./data/synth/labels"
              fi
              
              # Verify that spectrograms and labels exist in the expected location
              SPEC_COUNT=$(find ./data/synth/spectrograms -type f -name "*.npy" | wc -l)
              LABEL_COUNT=$(find ./data/synth/labels -type f -name "*.lab" | wc -l)
              echo "Found $SPEC_COUNT spectrogram files and $LABEL_COUNT label files"
              
              # Before starting training, verify data exists
              if [ "$SPEC_COUNT" -eq 0 ] || [ "$LABEL_COUNT" -eq 0 ]; then
                echo "WARNING: No data found in the expected paths"
                echo "Looking for data in alternate locations..."
                
                ALT_SPEC_COUNT=$(find /mnt/storage -type f -name "*.npy" | wc -l)
                ALT_LABEL_COUNT=$(find /mnt/storage -type f -name "*.lab" | wc -l)
                echo "Found $ALT_SPEC_COUNT .npy files and $ALT_LABEL_COUNT .lab files in alternate locations"
                
                # Show where the files were found
                if [ "$ALT_SPEC_COUNT" -gt 0 ]; then
                  echo "Sample spectrogram locations:"
                  find /mnt/storage -type f -name "*.npy" | head -5
                fi
                
                if [ "$ALT_LABEL_COUNT" -gt 0 ]; then
                  echo "Sample label locations:"
                  find /mnt/storage -type f -name "*.lab" | head -5
                fi
              fi
              
              # Get LR schedule option from environment
              LR_SCHEDULE_ARG=""
              if [ "${LR_SCHEDULE}" != "" ] && [ "${LR_SCHEDULE}" != "null" ]; then
                echo "Using ${LR_SCHEDULE} learning rate schedule"
                LR_SCHEDULE_ARG="--lr_schedule ${LR_SCHEDULE}"
              elif [ "${USE_WARMUP}" == "true" ]; then
                echo "Using warm-up learning rate schedule for ${WARMUP_EPOCHS} epochs"
                LR_SCHEDULE_ARG="--use_warmup --warmup_epochs ${WARMUP_EPOCHS}"
              else
                echo "Using default validation-based learning rate adjustment"
              fi
              
              # Get focal loss arguments
              FOCAL_LOSS_ARG=""
              if [ "${USE_FOCAL_LOSS}" == "true" ]; then
                echo "Using focal loss with gamma=${FOCAL_GAMMA}"
                FOCAL_LOSS_ARG="--use_focal_loss --focal_gamma ${FOCAL_GAMMA}"
                # Add focal_alpha if specified
                if [ "${FOCAL_ALPHA}" != "" ]; then
                  FOCAL_LOSS_ARG="${FOCAL_LOSS_ARG} --focal_alpha ${FOCAL_ALPHA}"
                fi
              fi
              
              # Get knowledge distillation arguments
              KD_LOSS_ARG=""
              if [ "${USE_KD_LOSS}" == "true" ]; then
                echo "Using knowledge distillation with alpha=${KD_ALPHA} and temperature=${TEMPERATURE}"
                KD_LOSS_ARG="--use_kd_loss --kd_alpha ${KD_ALPHA} --temperature ${TEMPERATURE}"
                echo "Note: Teacher logits must be included in the batch data"
              fi
              
              # Get model scale from environment
              MODEL_SCALE_ARG=""
              if [ "${MODEL_SCALE}" != "" ] && [ "${MODEL_SCALE}" != "1.0" ]; then
                echo "Using model scale factor: ${MODEL_SCALE}"
                MODEL_SCALE_ARG="--model_scale ${MODEL_SCALE}"
              else
                echo "Using default model scale (1.0)"
              fi
              
              # Handle caching options for memory optimization
              CACHE_ARGS=""
              if [ "${METADATA_CACHE}" == "true" ]; then
                echo "Using metadata-only caching to reduce memory usage"
                CACHE_ARGS="--metadata_cache"
              else
                echo "Dataset caching disabled to reduce memory usage"
                CACHE_ARGS="--disable_cache"
              fi
              
              # Add cache fraction argument
              if [ "${CACHE_FRACTION}" != "" ] && [ "${CACHE_FRACTION}" != "1.0" ]; then
                echo "Using partial dataset caching: ${CACHE_FRACTION} of samples"
                CACHE_ARGS="${CACHE_ARGS} --cache_fraction ${CACHE_FRACTION}"
              fi
              
              # Handle KD paths when KD is enabled with more flexible configuration
              if [ "${USE_KD_LOSS}" == "true" ]; then
                echo "Knowledge distillation enabled - using teacher logits"
                
                # Check if KD_DATA_ROOT exists
                if [ -d "${KD_DATA_ROOT}" ]; then
                  echo "Using KD data from: ${KD_DATA_ROOT}"
                  
                  # Define paths based on directory structure
                  if [ -d "${KD_DATA_ROOT}/spectrograms" ] && [ -d "${KD_DATA_ROOT}/labels" ] && [ -d "${KD_DATA_ROOT}/logits" ]; then
                    # Standard structure with separate directories
                    KD_ARGS="--spec_dir ${KD_DATA_ROOT}/spectrograms --label_dir ${KD_DATA_ROOT}/labels --logits_dir ${KD_DATA_ROOT}/logits"
                    echo "Using standard KD directory structure"
                  elif [ -d "${KD_DATA_ROOT}" ]; then
                    # All files might be in the root directory
                    KD_ARGS="--spec_dir ${KD_DATA_ROOT} --label_dir ${KD_DATA_ROOT} --logits_dir ${KD_DATA_ROOT}"
                    echo "Using flat KD directory structure"
                  else
                    echo "WARNING: Could not determine KD directory structure, using defaults"
                    KD_ARGS="--logits_dir ${KD_DATA_ROOT}"
                  fi
                else
                  echo "WARNING: KD_DATA_ROOT does not exist: ${KD_DATA_ROOT}"
                  echo "Attempting to use default paths"
                  KD_ARGS="--logits_dir /mnt/storage/data/logits/synth/logits"
                fi
                
                # Log the actual paths being used
                echo "KD arguments: ${KD_ARGS}"
              else
                KD_ARGS=""
              fi
              
              # Run the student training script with all options
              echo "Starting student training with updated script and all options..."
              python train_student.py --config ./config/student_config.yaml --save_dir checkpoints/student \
                ${LR_SCHEDULE_ARG} ${FOCAL_LOSS_ARG} ${KD_LOSS_ARG} ${MODEL_SCALE_ARG} ${CACHE_ARGS} ${KD_ARGS}
              
              echo "=== Student model training complete ==="
          resources:
            requests:
              cpu: "4"             
              memory: "12Gi"    
              nvidia.com/gpu: "1"
            limits:
              cpu: "6"             
              memory: "16Gi" 
              nvidia.com/gpu: "1"
          volumeMounts:
            - name: storage
              mountPath: /mnt/storage
      volumes:
        - name: storage
          persistentVolumeClaim:
            claimName: temporary-storage